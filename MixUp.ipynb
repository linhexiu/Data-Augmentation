{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyODIrmbkt7eWQMH59JTfCxo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/linhexiu/Data-Augmentation/blob/main/MixUp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MixUp:数据增强策略； 以下主要用于自我学习整理； 代码来源：https://gitcode.net/mirrors/facebookresearch/mixup-cifar10\n",
        "\n",
        "\n",
        "```\n",
        "acc. \n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pRR8wPgYJW4n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi -i 0\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "print(gpu_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oE6c1BsJJX1_",
        "outputId": "368dc8dd-a01e-4905-dc40-005acc43512a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Nov 17 03:56:20 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import csv\n",
        "import os\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "8Lw9sl9ZKGcX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parser = argparse.ArgumentParser(description='PyTorch CIFAR10 Training')\n",
        "parser.add_argument('--lr', default=0.1, type=float, help='learning rate')\n",
        "parser.add_argument('--resume', '-r', action='store_true',\n",
        "                    help='resume from checkpoint')\n",
        "parser.add_argument('--model', default=\"ResNet18\", type=str,\n",
        "                    help='model type (default: ResNet18)')\n",
        "parser.add_argument('--name', default='mixup', type=str, help='name of run')\n",
        "parser.add_argument('--seed', default=20221117, type=int, help='random seed')\n",
        "parser.add_argument('--batch-size', default=128, type=int, help='batch size')\n",
        "parser.add_argument('--epoch', default=200, type=int,\n",
        "                    help='total epochs to run')\n",
        "parser.add_argument('--no-augment', dest='augment', action='store_false',\n",
        "                    help='use standard augmentation (default: True)')\n",
        "parser.add_argument('--decay', default=1e-4, type=float, help='weight decay')\n",
        "parser.add_argument('--alpha', default=1., type=float,\n",
        "                    help='mixup interpolation coefficient (default: 1)')\n",
        "args = parser.parse_args('')\n",
        "print(args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnwkFrYgKS2e",
        "outputId": "4349ae4a-f372-45f7-aec8-8c5f3abb2948"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(alpha=1.0, augment=True, batch_size=128, decay=0.0001, epoch=200, lr=0.1, model='ResNet18', name='mixup', resume=False, seed=20221117)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "print(use_cuda)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4Cvn7qKLUtf",
        "outputId": "e044f422-6c40-4d26-d550-641082a5cdae"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_acc = 0\n",
        "start_epoch = 0\n",
        "\n",
        "if args.seed != 0:\n",
        "  torch.manual_seed(args.seed)"
      ],
      "metadata": {
        "id": "94QNa-tHLdJG"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data\n",
        "print(\"==> Preparing data ... \")\n",
        "if args.augment:\n",
        "  transform_train=transforms.Compose([\n",
        "      transforms.RandomCrop(32,padding=4),\n",
        "      transforms.RandomHorizontalFlip(),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "  ])\n",
        "else:\n",
        "  transfrom_train=transforms.Compose([\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),   \n",
        "  ])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "trainset=datasets.CIFAR10(root='data', train=True, download=True, transform=transform_train)\n",
        "trainloader=torch.utils.data.DataLoader(trainset, batch_size=args.batch_size, shuffle=True, num_workers=8)\n",
        "\n",
        "testset=datasets.CIFAR10(root='data', train=False, download=True, transform=transform_test)\n",
        "testloader=torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnsqZ-beL0HH",
        "outputId": "fb8125b2-f4f7-471b-cc0b-a1ee9bb0a8ed"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Preparing data ... \n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ResNet18\n",
        "\n",
        "'''ResNet in PyTorch.\n",
        "\n",
        "BasicBlock and Bottleneck module is from the original ResNet paper:\n",
        "[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n",
        "    Deep Residual Learning for Image Recognition. arXiv:1512.03385\n",
        "\n",
        "PreActBlock and PreActBottleneck module is from the later paper:\n",
        "[2] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n",
        "    Identity Mappings in Deep Residual Networks. arXiv:1603.05027\n",
        "'''\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = conv3x3(in_planes, planes, stride)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class PreActBlock(nn.Module):\n",
        "    '''Pre-activation version of the BasicBlock.'''\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(PreActBlock, self).__init__()\n",
        "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
        "        self.conv1 = conv3x3(in_planes, planes, stride)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(x))\n",
        "        shortcut = self.shortcut(out)\n",
        "        out = self.conv1(out)\n",
        "        out = self.conv2(F.relu(self.bn2(out)))\n",
        "        out += shortcut\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        out = self.bn3(self.conv3(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class PreActBottleneck(nn.Module):\n",
        "    '''Pre-activation version of the original Bottleneck module.'''\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(PreActBottleneck, self).__init__()\n",
        "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(x))\n",
        "        shortcut = self.shortcut(out)\n",
        "        out = self.conv1(out)\n",
        "        out = self.conv2(F.relu(self.bn2(out)))\n",
        "        out = self.conv3(F.relu(self.bn3(out)))\n",
        "        out += shortcut\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "\n",
        "        self.conv1 = conv3x3(3,64)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x, lin=0, lout=5):\n",
        "        out = x\n",
        "        if lin < 1 and lout > -1:\n",
        "            out = self.conv1(out)\n",
        "            out = self.bn1(out)\n",
        "            out = F.relu(out)\n",
        "        if lin < 2 and lout > 0:\n",
        "            out = self.layer1(out)\n",
        "        if lin < 3 and lout > 1:\n",
        "            out = self.layer2(out)\n",
        "        if lin < 4 and lout > 2:\n",
        "            out = self.layer3(out)\n",
        "        if lin < 5 and lout > 3:\n",
        "            out = self.layer4(out)\n",
        "        if lout > 4:\n",
        "            out = F.avg_pool2d(out, 4)\n",
        "            out = out.view(out.size(0), -1)\n",
        "            out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "def ResNet18():\n",
        "    return ResNet(PreActBlock, [2,2,2,2])\n",
        "\n",
        "def ResNet34():\n",
        "    return ResNet(BasicBlock, [3,4,6,3])\n",
        "\n",
        "def ResNet50():\n",
        "    return ResNet(Bottleneck, [3,4,6,3])\n",
        "\n",
        "def ResNet101():\n",
        "    return ResNet(Bottleneck, [3,4,23,3])\n",
        "\n",
        "def ResNet152():\n",
        "    return ResNet(Bottleneck, [3,8,36,3])\n",
        "\n",
        "\n",
        "def test():\n",
        "    net = ResNet18()\n",
        "    y = net(Variable(torch.randn(1,3,32,32)))\n",
        "    print(y.size())\n",
        "\n",
        "# test()\n"
      ],
      "metadata": {
        "id": "yej4ChXkT4b4"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model\n",
        "if args.resume:\n",
        "  print(\"==> Resuming from checkpoint ... \")\n",
        "  assert os.path.isdir('checkpoint'), 'Error: no checkpoint directory found!'\n",
        "  checkpoint = torch.load('./checkpoint/ckpt.t7' + args.name + '_'\n",
        "                            + str(args.seed))\n",
        "  net = checkpoint['net']\n",
        "  best_acc = checkpoint['acc']\n",
        "  start_epoch = checkpoint['epoch'] + 1\n",
        "  rng_state = checkpoint['rng_state']\n",
        "  torch.set_rng_state(rng_state)\n",
        "else:\n",
        "  print('==> Building model..')\n",
        "  net = ResNet18()\n",
        "\n",
        "print(net)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkiH-1dbOHGt",
        "outputId": "015a338d-4322-4ff4-a64e-ae72cb3c392e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Building model..\n",
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (layer1): Sequential(\n",
            "    (0): PreActBlock(\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "    (1): PreActBlock(\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): PreActBlock(\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (1): PreActBlock(\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): PreActBlock(\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (1): PreActBlock(\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): PreActBlock(\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (1): PreActBlock(\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "  )\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.isdir('results'):\n",
        "    os.mkdir('results')\n",
        "\n",
        "logname = ('results/log_' + '_' + args.name + '_'\n",
        "           + str(args.seed) + '.csv')\n",
        "if use_cuda:\n",
        "    net.cuda()\n",
        "    net = torch.nn.DataParallel(net)\n",
        "    print(torch.cuda.device_count())\n",
        "    cudnn.benchmark = True\n",
        "    print('Using CUDA..')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48TR4VDeVLCJ",
        "outputId": "474804df-b410-42e0-c8ea-f626a482ca50"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "Using CUDA..\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=args.lr, momentum=0.9,\n",
        "                      weight_decay=args.decay)\n",
        "\n",
        "def mixup_data(x, y, alpha=1.0, use_cuda=True):\n",
        "  if alpha > 0:\n",
        "    lam = np.random.beta(alpha, alpha)\n",
        "  else:\n",
        "    lam = 1\n",
        "\n",
        "  batch_size = x.size()[0]\n",
        "  if use_cuda:\n",
        "    index = torch.randperm(batch_size).cuda()\n",
        "  else:\n",
        "    index = torch.randperm(batch_size)\n",
        "  \n",
        "  mixed_x = lam * x + (1 - lam) * x[index, :]\n",
        "  y_a, y_b = y, y[index]\n",
        "  return mixed_x, y_a, y_b, lam"
      ],
      "metadata": {
        "id": "-VTuEFbYVpo8"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
        "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)"
      ],
      "metadata": {
        "id": "54jfHMw8XTHJ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(epoch):\n",
        "  net.train()\n",
        "  train_loss = 0.0\n",
        "  reg_loss = 0.0\n",
        "  correct = 0.0\n",
        "  total = 0\n",
        "  train_bar = tqdm(trainloader)\n",
        "  for inputs, targets in trainloader:\n",
        "    if use_cuda:\n",
        "      inputs, targets = inputs.cuda(), targets.cuda()\n",
        "\n",
        "    inputs, targets_a, targets_b, lam = mixup_data(inputs, targets, args.alpha, use_cuda)\n",
        "\n",
        "\n",
        "    inputs, targets_a, targets_b = map(Variable, (inputs, targets_a, targets_b))\n",
        "\n",
        "    outputs = net(inputs)\n",
        "    loss = mixup_criterion(criterion, outputs, targets_a, targets_b, lam)\n",
        "    train_loss += loss.item() * trainloader.batch_size # *128\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += targets.size(0)\n",
        "    correct += (lam * predicted.eq(targets_a.data).cpu().sum().float()\n",
        "            + (1 - lam) * predicted.eq(targets_b.data).cpu().sum().float())\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_bar.set_description('Train Epoch: [{}/{}], Loss: {:.4f}, Reg: {:.4f}, Acc: {:.4f}%'.format(epoch, args.epoch, train_loss/total, reg_loss/total, 100.*correct/total))\n",
        "  return (train_loss/total, reg_loss/total, 100.*correct/total)"
      ],
      "metadata": {
        "id": "aRCbpnKiXT6q"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(epoch):\n",
        "  global best_acc\n",
        "  net.eval()\n",
        "  test_loss=0.0\n",
        "  correct=0.0\n",
        "  total=0\n",
        "  test_bar = tqdm(testloader)\n",
        "  for inputs, targets in testloader:\n",
        "    if use_cuda:\n",
        "      inputs, targets = inputs.cuda(), targets.cuda()\n",
        "    inputs, targets = Variable(inputs, volatile=True), Variable(targets)\n",
        "    outputs = net(inputs)\n",
        "    loss = criterion(outputs, targets)\n",
        "    test_loss += loss.data * testloader.batch_size\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += targets.size(0)\n",
        "    correct += predicted.eq(targets.data).cpu().sum()\n",
        "    test_bar.set_description('Test Epoch: [{}/{}], Loss: {:.4f}, Acc: {:.4f}%'.format(epoch, args.epoch, test_loss/total, 100.*correct/total))\n",
        "  acc = 100.* correct/total\n",
        "  if epoch == start_epoch + args.epoch - 1 or acc > best_acc:\n",
        "    checkpoint(acc, epoch)\n",
        "  if acc > best_acc:\n",
        "      best_acc = acc\n",
        "  return (test_loss/total, acc)"
      ],
      "metadata": {
        "id": "uHmXSW0cbvNL"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def checkpoint(acc, epoch):\n",
        "    # Save checkpoint.\n",
        "    print('Saving..')\n",
        "    state = {\n",
        "        'net': net,\n",
        "        'acc': acc,\n",
        "        'epoch': epoch,\n",
        "        'rng_state': torch.get_rng_state()\n",
        "    }\n",
        "    if not os.path.isdir('checkpoint'):\n",
        "        os.mkdir('checkpoint')\n",
        "    torch.save(state, './checkpoint/ckpt.t7' + args.name + '_'\n",
        "               + str(args.seed))"
      ],
      "metadata": {
        "id": "FknUBHd3c9ye"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def adjust_learning_rate(optimizer, epoch):\n",
        "    \"\"\"decrease the learning rate at 100 and 150 epoch\"\"\"\n",
        "    lr = args.lr\n",
        "    if epoch >= 100:\n",
        "        lr /= 10\n",
        "    if epoch >= 150:\n",
        "        lr /= 10\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr"
      ],
      "metadata": {
        "id": "dREBG_JkbtVn"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists(logname):\n",
        "    with open(logname, 'w') as logfile:\n",
        "        logwriter = csv.writer(logfile, delimiter=',')\n",
        "        logwriter.writerow(['epoch', 'train loss', 'reg loss', 'train acc',\n",
        "                            'test loss', 'test acc'])"
      ],
      "metadata": {
        "id": "flf_ER43dFLc"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(start_epoch, args.epoch):\n",
        "    train_loss, reg_loss, train_acc = train(epoch)\n",
        "    test_loss, test_acc = test(epoch)\n",
        "    adjust_learning_rate(optimizer, epoch)\n",
        "    with open(logname, 'a') as logfile:\n",
        "        logwriter = csv.writer(logfile, delimiter=',')\n",
        "        logwriter.writerow([epoch, train_loss, reg_loss, train_acc, test_loss,\n",
        "                            test_acc])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axiOqdCodJam",
        "outputId": "ce0e2c37-97cb-416d-d9c6-17e9965265bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/391 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Train Epoch: [0/200], Loss: 1.4298, Reg: 0.0000, Acc: 56.6740%:   0%|          | 0/391 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Train Epoch: [0/200], Loss: 1.2377, Reg: 0.0000, Acc: 65.6903%:   0%|          | 0/391 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Train Epoch: [0/200], Loss: 1.0829, Reg: 0.0000, Acc: 70.5248%:   0%|          | 0/391 [00:01<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Train Epoch: [0/200], Loss: 1.0593, Reg: 0.0000, Acc: 70.5704%:   0%|          | 0/391 [00:01<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Train Epoch: [0/200], Loss: 1.1797, Reg: 0.0000, Acc: 65.4775%:   0%|          | 0/391 [00:01<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Train Epoch: [0/200], Loss: 1.2183, Reg: 0.0000, Acc: 64.3523%:   0%|          | 0/391 [00:01<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Train Epoch: [0/200], Loss: 1.2473, Reg: 0.0000, Acc: 62.9645%:   0%|          | 0/391 [00:01<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Train Epoch: [0/200], Loss: 1.2580, Reg: 0.0000, Acc: 62.9737%:   0%|          | 0/391 [00:01<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Train Epoch: [0/200], Loss: 1.3033, Reg: 0.0000, Acc: 60.6388%:   0%|          | 0/391 [00:01<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Train Epoch: [0/200], Loss: 1.4359, Reg: 0.0000, Acc: 54.4387%:   0%|          | 0/391 [07:22<?, ?it/s]\n",
            "Test Epoch: [0/200], Loss: 0.7449, Acc: 76.7500%:   0%|          | 0/100 [06:08<?, ?it/s]\n",
            "  0%|          | 0/100 [04:51<?, ?it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Train Epoch: [0/200], Loss: 1.4359, Reg: 0.0000, Acc: 54.4387%:   0%|          | 0/391 [07:22<?, ?it/s]\n",
            "Test Epoch: [0/200], Loss: 0.7449, Acc: 76.7500%:   0%|          | 0/100 [06:08<?, ?it/s]\n",
            "Train Epoch: [0/200], Loss: 1.4359, Reg: 0.0000, Acc: 54.4387%:   0%|          | 0/391 [07:22<?, ?it/s]\n",
            "Test Epoch: [0/200], Loss: 0.7449, Acc: 76.7500%:   0%|          | 0/100 [06:08<?, ?it/s]\n",
            "  0%|          | 0/100 [04:51<?, ?it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/100 [04:51<?, ?it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Train Epoch: [0/200], Loss: 1.4359, Reg: 0.0000, Acc: 54.4387%:   0%|          | 0/391 [07:22<?, ?it/s]\n",
            "Test Epoch: [0/200], Loss: 0.7449, Acc: 76.7500%:   0%|          | 0/100 [06:08<?, ?it/s]\n",
            "  0%|          | 0/100 [04:51<?, ?it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Train Epoch: [0/200], Loss: 1.4359, Reg: 0.0000, Acc: 54.4387%:   0%|          | 0/391 [07:22<?, ?it/s]\n",
            "Test Epoch: [0/200], Loss: 0.7449, Acc: 76.7500%:   0%|          | 0/100 [06:08<?, ?it/s]\n",
            "  0%|          | 0/100 [04:52<?, ?it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Train Epoch: [0/200], Loss: 1.1827, Reg: 0.0000, Acc: 64.8282%:   0%|          | 0/391 [00:02<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Train Epoch: [0/200], Loss: 1.4359, Reg: 0.0000, Acc: 54.4387%:   0%|          | 0/391 [07:22<?, ?it/s]\n",
            "Test Epoch: [0/200], Loss: 0.7449, Acc: 76.7500%:   0%|          | 0/100 [06:08<?, ?it/s]\n",
            "  0%|          | 0/100 [04:52<?, ?it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Train Epoch: [0/200], Loss: 1.4359, Reg: 0.0000, Acc: 54.4387%:   0%|          | 0/391 [07:23<?, ?it/s]\n",
            "Test Epoch: [0/200], Loss: 0.7449, Acc: 76.7500%:   0%|          | 0/100 [06:08<?, ?it/s]\n",
            "  0%|          | 0/100 [04:52<?, ?it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Train Epoch: [0/200], Loss: 1.2527, Reg: 0.0000, Acc: 61.7445%:   0%|          | 0/391 [00:02<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Train Epoch: [0/200], Loss: 1.2736, Reg: 0.0000, Acc: 60.5010%:   0%|          | 0/391 [00:02<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Train Epoch: [0/200], Loss: 1.4359, Reg: 0.0000, Acc: 54.4387%:   0%|          | 0/391 [07:23<?, ?it/s]\n",
            "Test Epoch: [0/200], Loss: 0.7449, Acc: 76.7500%:   0%|          | 0/100 [06:09<?, ?it/s]\n",
            "  0%|          | 0/100 [04:52<?, ?it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Train Epoch: [0/200], Loss: 1.2705, Reg: 0.0000, Acc: 60.6639%:   0%|          | 0/391 [00:03<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Train Epoch: [0/200], Loss: 1.2869, Reg: 0.0000, Acc: 60.0409%:   0%|          | 0/391 [00:03<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Train Epoch: [0/200], Loss: 1.2638, Reg: 0.0000, Acc: 60.8521%:   0%|          | 0/391 [00:03<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Train Epoch: [0/200], Loss: 1.2600, Reg: 0.0000, Acc: 61.1599%:   0%|          | 0/391 [00:03<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Train Epoch: [0/200], Loss: 1.2392, Reg: 0.0000, Acc: 61.9465%:   0%|          | 0/391 [00:03<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Train Epoch: [0/200], Loss: 1.2494, Reg: 0.0000, Acc: 61.4852%:   0%|          | 0/391 [00:03<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Train Epoch: [0/200], Loss: 1.2294, Reg: 0.0000, Acc: 61.9724%:   0%|          | 0/391 [00:03<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Train Epoch: [0/200], Loss: 1.2125, Reg: 0.0000, Acc: 62.5796%:   0%|          | 0/391 [00:03<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Train Epoch: [0/200], Loss: 1.2173, Reg: 0.0000, Acc: 62.5450%:   0%|          | 0/391 [00:03<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Train Epoch: [0/200], Loss: 1.2163, Reg: 0.0000, Acc: 62.7910%:   0%|          | 0/391 [00:04<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Train Epoch: [0/200], Loss: 1.2277, Reg: 0.0000, Acc: 62.2281%:   0%|          | 0/391 [00:04<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Train Epoch: [0/200], Loss: 1.2388, Reg: 0.0000, Acc: 61.7275%:   0%|          | 0/391 [00:04<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Train Epoch: [0/200], Loss: 1.2479, Reg: 0.0000, Acc: 61.4024%:   0%|          | 0/391 [00:04<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Train Epoch: [0/200], Loss: 1.2607, Reg: 0.0000, Acc: 60.8928%:   0%|          | 0/391 [00:04<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Train Epoch: [0/200], Loss: 1.2530, Reg: 0.0000, Acc: 61.2180%:   0%|          | 0/391 [00:04<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Train Epoch: [0/200], Loss: 1.2593, Reg: 0.0000, Acc: 61.1182%:   0%|          | 0/391 [00:04<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Train Epoch: [0/200], Loss: 1.2661, Reg: 0.0000, Acc: 60.8435%:   0%|          | 0/391 [00:04<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Train Epoch: [0/200], Loss: 1.2466, Reg: 0.0000, Acc: 61.4825%:   0%|          | 0/391 [00:04<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Train Epoch: [0/200], Loss: 1.2281, Reg: 0.0000, Acc: 62.1252%:   0%|          | 0/391 [00:04<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Train Epoch: [0/200], Loss: 1.2142, Reg: 0.0000, Acc: 62.5811%:   0%|          | 0/391 [00:05<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Train Epoch: [0/200], Loss: 1.2230, Reg: 0.0000, Acc: 62.1832%:   0%|          | 0/391 [00:05<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Train Epoch: [0/200], Loss: 1.2337, Reg: 0.0000, Acc: 61.7101%:   0%|          | 0/391 [00:05<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Train Epoch: [0/200], Loss: 1.2435, Reg: 0.0000, Acc: 61.2761%:   0%|          | 0/391 [00:05<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Train Epoch: [0/200], Loss: 1.2510, Reg: 0.0000, Acc: 61.0455%:   0%|          | 0/391 [00:05<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Train Epoch: [0/200], Loss: 1.2564, Reg: 0.0000, Acc: 60.8480%:   0%|          | 0/391 [00:05<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Train Epoch: [0/200], Loss: 1.2446, Reg: 0.0000, Acc: 61.2306%:   0%|          | 0/391 [00:05<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Train Epoch: [0/200], Loss: 1.2415, Reg: 0.0000, Acc: 61.4758%:   0%|          | 0/391 [00:05<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Train Epoch: [0/200], Loss: 1.2459, Reg: 0.0000, Acc: 61.3677%:   0%|          | 0/391 [00:05<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Train Epoch: [0/200], Loss: 1.2555, Reg: 0.0000, Acc: 60.9384%:   0%|          | 0/391 [00:05<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Train Epoch: [0/200], Loss: 1.2394, Reg: 0.0000, Acc: 61.4224%:   0%|          | 0/391 [00:05<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Train Epoch: [0/200], Loss: 1.2475, Reg: 0.0000, Acc: 61.0666%:   0%|          | 0/391 [00:06<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Train Epoch: [0/200], Loss: 1.2479, Reg: 0.0000, Acc: 61.1502%:   0%|          | 0/391 [00:06<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Train Epoch: [0/200], Loss: 1.2475, Reg: 0.0000, Acc: 61.2567%:   0%|          | 0/391 [00:06<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Train Epoch: [0/200], Loss: 1.2543, Reg: 0.0000, Acc: 61.0330%:   0%|          | 0/391 [00:06<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Train Epoch: [0/200], Loss: 1.2552, Reg: 0.0000, Acc: 61.0379%:   0%|          | 0/391 [00:06<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Train Epoch: [0/200], Loss: 1.2562, Reg: 0.0000, Acc: 61.1234%:   0%|          | 0/391 [00:06<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Train Epoch: [0/200], Loss: 1.2597, Reg: 0.0000, Acc: 61.0578%:   0%|          | 0/391 [00:06<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Train Epoch: [0/200], Loss: 1.2649, Reg: 0.0000, Acc: 60.8602%:   0%|          | 0/391 [00:06<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Train Epoch: [0/200], Loss: 1.2709, Reg: 0.0000, Acc: 60.5556%:   0%|          | 0/391 [00:06<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Train Epoch: [0/200], Loss: 1.2730, Reg: 0.0000, Acc: 60.4941%:   0%|          | 0/391 [00:06<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Train Epoch: [0/200], Loss: 1.2766, Reg: 0.0000, Acc: 60.3074%:   0%|          | 0/391 [00:06<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Train Epoch: [0/200], Loss: 1.2705, Reg: 0.0000, Acc: 60.5342%:   0%|          | 0/391 [00:07<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Train Epoch: [0/200], Loss: 1.2707, Reg: 0.0000, Acc: 60.5915%:   0%|          | 0/391 [00:07<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Train Epoch: [0/200], Loss: 1.2702, Reg: 0.0000, Acc: 60.6689%:   0%|          | 0/391 [00:07<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Train Epoch: [0/200], Loss: 1.2747, Reg: 0.0000, Acc: 60.4650%:   0%|          | 0/391 [00:07<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Train Epoch: [0/200], Loss: 1.2796, Reg: 0.0000, Acc: 60.3034%:   0%|          | 0/391 [00:07<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Train Epoch: [0/200], Loss: 1.2727, Reg: 0.0000, Acc: 60.5931%:   0%|          | 0/391 [00:07<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Train Epoch: [0/200], Loss: 1.2764, Reg: 0.0000, Acc: 60.5049%:   0%|          | 0/391 [00:07<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Train Epoch: [0/200], Loss: 1.2751, Reg: 0.0000, Acc: 60.6188%:   0%|          | 0/391 [00:07<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Train Epoch: [0/200], Loss: 1.2704, Reg: 0.0000, Acc: 60.8305%:   0%|          | 0/391 [00:07<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Train Epoch: [0/200], Loss: 1.2763, Reg: 0.0000, Acc: 60.5458%:   0%|          | 0/391 [00:07<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Train Epoch: [0/200], Loss: 1.2777, Reg: 0.0000, Acc: 60.5812%:   0%|          | 0/391 [00:07<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Train Epoch: [0/200], Loss: 1.2766, Reg: 0.0000, Acc: 60.6856%:   0%|          | 0/391 [00:08<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Train Epoch: [0/200], Loss: 1.2705, Reg: 0.0000, Acc: 60.9375%:   0%|          | 0/391 [00:08<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Train Epoch: [0/200], Loss: 1.2734, Reg: 0.0000, Acc: 60.8845%:   0%|          | 0/391 [00:08<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Train Epoch: [0/200], Loss: 1.2749, Reg: 0.0000, Acc: 60.8606%:   0%|          | 0/391 [00:08<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Train Epoch: [0/200], Loss: 1.2788, Reg: 0.0000, Acc: 60.7016%:   0%|          | 0/391 [00:08<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Train Epoch: [0/200], Loss: 1.2797, Reg: 0.0000, Acc: 60.7183%:   0%|          | 0/391 [00:08<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Train Epoch: [0/200], Loss: 1.2786, Reg: 0.0000, Acc: 60.7892%:   0%|          | 0/391 [00:08<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
          ]
        }
      ]
    }
  ]
}